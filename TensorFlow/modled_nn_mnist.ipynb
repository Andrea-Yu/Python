{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "tf.reset_default_graph()\n",
    "\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 Loss: 0.172248676 Accuracy: 0.9520\n",
      "Epoch: 02 Loss: 0.151537746 Accuracy: 0.9578\n",
      "Epoch: 03 Loss: 0.126806095 Accuracy: 0.9706\n",
      "Epoch: 04 Loss: 0.125573605 Accuracy: 0.9678\n",
      "Epoch: 05 Loss: 0.138096437 Accuracy: 0.9658\n",
      "mnist_265_64_m000005.ckpt saver\n",
      "Epoch: 06 Loss: 0.191718429 Accuracy: 0.9608\n",
      "Epoch: 07 Loss: 0.162698314 Accuracy: 0.9712\n",
      "Epoch: 08 Loss: 0.155213013 Accuracy: 0.9620\n",
      "Epoch: 09 Loss: 0.154603943 Accuracy: 0.9732\n",
      "Epoch: 10 Loss: 0.123715870 Accuracy: 0.9734\n",
      "mnist_265_64_m000010.ckpt saver\n",
      "Epoch: 11 Loss: 0.165490240 Accuracy: 0.9712\n",
      "Epoch: 12 Loss: 0.177991107 Accuracy: 0.9722\n",
      "Epoch: 13 Loss: 0.149508908 Accuracy: 0.9748\n",
      "Epoch: 14 Loss: 0.181552991 Accuracy: 0.9706\n",
      "Epoch: 15 Loss: 0.177471086 Accuracy: 0.9688\n",
      "mnist_265_64_m000015.ckpt saver\n",
      "Epoch: 16 Loss: 0.197503045 Accuracy: 0.9686\n",
      "Epoch: 17 Loss: 0.175129667 Accuracy: 0.9738\n",
      "Epoch: 18 Loss: 0.171653599 Accuracy: 0.9714\n",
      "Epoch: 19 Loss: 0.171961501 Accuracy: 0.9756\n",
      "Epoch: 20 Loss: 0.224270657 Accuracy: 0.9722\n",
      "mnist_265_64_m000020.ckpt saver\n",
      "Epoch: 21 Loss: 0.207911327 Accuracy: 0.9718\n",
      "Epoch: 22 Loss: 0.221679583 Accuracy: 0.9726\n",
      "Epoch: 23 Loss: 0.201350346 Accuracy: 0.9752\n",
      "Epoch: 24 Loss: 0.228270680 Accuracy: 0.9712\n",
      "Epoch: 25 Loss: 0.272992641 Accuracy: 0.9698\n",
      "mnist_265_64_m000025.ckpt saver\n",
      "Epoch: 26 Loss: 0.213066876 Accuracy: 0.9736\n",
      "Epoch: 27 Loss: 0.266025603 Accuracy: 0.9726\n",
      "Epoch: 28 Loss: 0.265688330 Accuracy: 0.9728\n",
      "Epoch: 29 Loss: 0.252040297 Accuracy: 0.9688\n",
      "Epoch: 30 Loss: 0.252962708 Accuracy: 0.9744\n",
      "mnist_265_64_m000030.ckpt saver\n",
      "Epoch: 31 Loss: 0.228931293 Accuracy: 0.9710\n",
      "Epoch: 32 Loss: 0.224257693 Accuracy: 0.9704\n",
      "Epoch: 33 Loss: 0.216438815 Accuracy: 0.9750\n",
      "Epoch: 34 Loss: 0.248282269 Accuracy: 0.9716\n",
      "Epoch: 35 Loss: 0.279965520 Accuracy: 0.9742\n",
      "mnist_265_64_m000035.ckpt saver\n",
      "Epoch: 36 Loss: 0.305245012 Accuracy: 0.9740\n",
      "Epoch: 37 Loss: 0.358904123 Accuracy: 0.9724\n",
      "Epoch: 38 Loss: 0.294623733 Accuracy: 0.9712\n",
      "Epoch: 39 Loss: 0.286121041 Accuracy: 0.9722\n",
      "Epoch: 40 Loss: 0.280470103 Accuracy: 0.9716\n",
      "mnist_265_64_m000040.ckpt saver\n",
      "Model saved!\n",
      "Finished. Train takes 319.57 duration\n"
     ]
    }
   ],
   "source": [
    "# 构建模型\n",
    "# 此为两层NN示例\n",
    "H1_NN = 256\n",
    "H2_NN = 64\n",
    "\n",
    "# 定义全连接层函数\n",
    "def fcn_layer(inputs,           # 数入数据\n",
    "              input_dim,        # 输入神经元数量\n",
    "              output_dim,       # 输出神经元数量\n",
    "              activation=None): # 激活函数\n",
    "    \n",
    "    # 以截断正态分布的随机函数初始化\n",
    "    W = tf.Variable(tf.truncated_normal([input_dim, output_dim], stddev=0.1))\n",
    "    # 以0初始化b\n",
    "    b = tf.Variable(tf.zeros([output_dim]))\n",
    "    \n",
    "    # 建立权重计算\n",
    "    XWb = tf.matmul(inputs, W) + b\n",
    "    \n",
    "    # 激活函数\n",
    "    if activation is None:\n",
    "        outputs = XWb\n",
    "    else:\n",
    "        outputs = activation(XWb)\n",
    "        \n",
    "    return outputs\n",
    "\n",
    "# 建构双隐层模型\n",
    "# 输入层\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='X')\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='Y')\n",
    "# 隐藏层1\n",
    "h1 = fcn_layer(x, 784, H1_NN, tf.nn.relu)\n",
    "# 隐藏层2\n",
    "h2 = fcn_layer(h1, H1_NN, H2_NN, tf.nn.relu)\n",
    "# 输出层\n",
    "forward = fcn_layer(h2, H2_NN, 10, None)\n",
    "pred = tf.nn.softmax(forward)\n",
    "\n",
    "# 关于训练模型与保存\n",
    "\n",
    "# 初始化参数和文件目录\n",
    "# 存储模型的粒度\n",
    "save_step = 5\n",
    "# 创建保存模型文件的目录\n",
    "import os\n",
    "ckpt_dir = './ckpt_dir'\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir)\n",
    "\n",
    "# 训练并存储模型\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# 基础参数\n",
    "train_epoch = 40\n",
    "report_step = 1\n",
    "learning_step = 0.01\n",
    "batch_size = 50\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "# 定义损失函数\n",
    "loss_func = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=forward, labels=y))\n",
    "\n",
    "# 定义优化选择器\n",
    "optimizer = tf.train.AdamOptimizer(learning_step).minimize(loss_func)\n",
    "\n",
    "# 定义准确率\n",
    "correct_pred = tf.equal(tf.argmax(y, 1), tf.argmax(pred, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 训练模型\n",
    "from time import time\n",
    "startTime = time()\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for epoch in range(train_epoch):\n",
    "    for batch in range(total_batch):\n",
    "        xs, ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optimizer, feed_dict={x: xs, y: ys})\n",
    "    \n",
    "    loss, acc = sess.run([loss_func, accuracy], feed_dict={x: mnist.validation.images, y: mnist.validation.labels})\n",
    "    \n",
    "    if (epoch + 1) % report_step == 0:\n",
    "        print('Epoch: %02d' % (epoch+1), 'Loss: %.9f' % (loss), 'Accuracy: %.4f' % (acc))\n",
    "        \n",
    "    \n",
    "    if (epoch + 1) % save_step == 0:\n",
    "        # 存储模型\n",
    "        saver.save(sess, os.path.join(ckpt_dir, 'mnist_265_64_m{:06d}.ckpt'.format(epoch+1)))\n",
    "        print('mnist_265_64_m{:06d}.ckpt saver'.format(epoch+1))\n",
    "        \n",
    "saver.save(sess, os.path.join(ckpt_dir, 'mnist_265_64_m.ckpt'))\n",
    "print('Model saved!')\n",
    "    \n",
    "# 显示运行时间\n",
    "duration = time() - startTime\n",
    "print('Finished. Train takes %.2f duration' % (duration))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9676\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
